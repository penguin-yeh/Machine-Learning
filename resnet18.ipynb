{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UvmWqwvdLps"
      },
      "source": [
        "## initial setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ae24qy8cL6L",
        "outputId": "d79f3d7f-f36f-40a8-d638-cc30fac9ede7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Colab Notebooks/ai cup\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks/ai cup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0LXM0OcbXky"
      },
      "source": [
        "## import "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjF8oVZLbIZk"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "!pip install --upgrade numpy\n",
        "\n",
        "from torch.optim import lr_scheduler\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_93_6KX-bqWP"
      },
      "source": [
        "##  image pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oK184g4b2Ms"
      },
      "outputs": [],
      "source": [
        "# 資料轉換函數\n",
        "data_transforms = {\n",
        "    # 訓練資料集採用資料增強與標準化轉換\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224), # 隨機剪裁並縮放\n",
        "        transforms.RandomHorizontalFlip(), # 隨機水平翻轉\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 標準化\n",
        "    ]),\n",
        "    # 驗證資料集僅採用資料標準化轉換\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),  # 縮放\n",
        "        transforms.CenterCrop(224), # 中央剪裁\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 標準化\n",
        "    ]),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHsMUC12wYPV"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnM2Gq6hccDJ"
      },
      "source": [
        "## get filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PotocpcOtG7V"
      },
      "outputs": [],
      "source": [
        "class ImageFolderWithPaths(datasets.ImageFolder):\n",
        "    \"\"\"Custom dataset that includes image file paths. Extends\n",
        "    torchvision.datasets.ImageFolder\n",
        "    \"\"\"\n",
        "\n",
        "    # override the __getitem__ method. this is the method that dataloader calls\n",
        "    def __getitem__(self, index):\n",
        "        # this is what ImageFolder normally returns \n",
        "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
        "        # the image file path\n",
        "        path = self.imgs[index][0]\n",
        "        # make a new tuple that includes original and the path\n",
        "        tuple_with_path = (original_tuple + (path,))\n",
        "        return tuple_with_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1YeiGXwyaXZ"
      },
      "outputs": [],
      "source": [
        "!pwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2TmGOkktEGb"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gKQF756cgPj"
      },
      "outputs": [],
      "source": [
        "  # 資料集載入 =======================================================================\n",
        "data_dir = './dataset/training'\n",
        "\n",
        "image_datasets = {        \n",
        "  x: ImageFolderWithPaths(    #默認已經將不同類型的image分成不同的folder\n",
        "    os.path.join(data_dir, x), #path\n",
        "    data_transforms[x]\n",
        "  ) \n",
        "  for x in ['train', 'val']\n",
        "}\n",
        "\n",
        "#print(image_datasets['train'].imgs[22][0])  #class:train底下的已經分類好的img, type\n",
        "                        # imgs[1][0] => 1st img's filename\n",
        "                        # imgs[1][1] => 1st img's type \n",
        "#print(image_datasets['train'].imgs[22][1])\n",
        "#print(image_datasets['train'].classes) #class:train底下的已經分類好的folder的name\n",
        "#print(image_datasets['train'][7][1])  #1st: [7]=>7th img(from start)\n",
        "                    #2nd: [0]=>img information\n",
        "                    #   [1]=>label(folder name)\n",
        "\n",
        "dataloaders = {    \n",
        "  x: torch.utils.data.DataLoader(  #define how to sampling(batch...)\n",
        "    image_datasets[x],       #dataset\n",
        "    batch_size=8,         #how many samples per batch to load \n",
        "    shuffle=True,         #資料打亂 reshuffle at every epoch\n",
        "    num_workers=2         #how many subprocess to load dataset\n",
        "                    #0 => only main function => slow\n",
        "                    #1 => only one subprocess => slow too\n",
        "  )\n",
        "  for x in ['train', 'val']\n",
        "}\n",
        "#print(dataloaders['train'])\n",
        "\n",
        "## 取得訓練資料集與驗證資料集的資料量\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} #how many img in train/val\n",
        "print(dataset_sizes)\n",
        "\n",
        "# 取得各類別的名稱\n",
        "class_names = image_datasets['train'].classes\n",
        "print(class_names)\n",
        "\n",
        "#get data of batch size\n",
        "inputs, classes, paths = next(iter(dataloaders['train']))\n",
        "#classes_names = classes.tolist()\n",
        "for i in range(5):\n",
        "    #print(classes[i])\n",
        "    #print(paths[i])\n",
        "    idx = classes[i].item()\n",
        "    #print(idx)\n",
        "    #idx_string = str(idx)\n",
        "    #print(idx_string)\n",
        "    print(class_names[idx])\n",
        "\n",
        "# 若 CUDA 環境可用，則使用 GPU 計算，否則使用 CPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Awe9zzSLeoMM"
      },
      "source": [
        "## look data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxjHFtboer2N"
      },
      "outputs": [],
      "source": [
        "def tensor2img(inp):\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "3ALtug_4BKwD",
        "outputId": "3e5e8e9c-30ba-4b8a-d25c-d45862572d19"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ncol['filename'].append('apple')\\ncol['filename'].append('banana')\\n\\ncol['category'].append(1)\\ncol['category'].append(2)\\n\\ncol_df = pd.DataFrame(col)\\ncol_df.to_csv('label.csv', index=False)\\n\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "col = {'filename':[], 'category':[]}\n",
        "\n",
        "\"\"\"\n",
        "col['filename'].append('apple')\n",
        "col['filename'].append('banana')\n",
        "\n",
        "col['category'].append(1)\n",
        "col['category'].append(2)\n",
        "\n",
        "col_df = pd.DataFrame(col)\n",
        "col_df.to_csv('label.csv', index=False)\n",
        "\"\"\"\n",
        "\n",
        "#print(col['filename'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrMf7BnDhTSy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-WCFVThqRXf"
      },
      "source": [
        "## train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkzD1g_2pUqO"
      },
      "outputs": [],
      "source": [
        "# 將多張圖片拼成一張 grid 圖\n",
        "#out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "# 顯示圖片\n",
        "#img = tensor2img(out)\n",
        "#plt.imshow(img)\n",
        "#plt.title([class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0V2NfE0qTyU"
      },
      "outputs": [],
      "source": [
        "# 訓練模型用函數\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time() # 記錄開始時間\n",
        "\n",
        "    # 記錄最佳模型\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_1 = []\n",
        "    best_2 = []\n",
        "\n",
        "    # 訓練模型主迴圈\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # 對於每個 epoch，分別進行訓練模型與驗證模型\n",
        "        for phase in ['train', 'val']:\n",
        "\n",
        "            temp_1 = []\n",
        "            temp_2 = []\n",
        "\n",
        "            if phase == 'train':\n",
        "                model.train()  # 將模型設定為訓練模式\n",
        "            else:\n",
        "                model.eval()   # 將模型設定為驗證模式\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            # 以 DataLoader 載入 batch 資料\n",
        "            for inputs, labels, paths in tqdm(dataloaders[phase]):\n",
        "                # 將資料放置於 GPU 或 CPU\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # 重設參數梯度（gradient）\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 只在訓練模式計算參數梯度\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # 正向傳播（forward）\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()  # 反向傳播（backward）\n",
        "                        optimizer.step() # 更新參數\n",
        "                '''    \n",
        "                for item in paths:\n",
        "                  path = os.path.dirname(item)\n",
        "                  #print(path)\n",
        "                  path = os.path.basename(path)\n",
        "                  #print(path)\n",
        "                '''\n",
        "                \n",
        "                # 計算統計值\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                #temp = dict(zip(paths, preds))\n",
        "                '''\n",
        "                for item, x in zip(paths, labels):\n",
        "                    print('filename : ' + item, end = ' ')\n",
        "                    idx = x.item()\n",
        "                    idx_string = str(idx)\n",
        "                    print('labels : ',x.item(), end = ' ')\n",
        "                    print('class : ',class_names.index(idx_string))\n",
        "                '''\n",
        "\n",
        "                #zip\n",
        "                \n",
        "                if phase == 'val':\n",
        "                  for item, x in zip(paths, preds):\n",
        "                    #print(item)\n",
        "                    temp_1.append(os.path.basename(item))\n",
        "                    #print(preds[0])\n",
        "                    #print(x)\n",
        "                    idx = x.item()\n",
        "                    temp_2.append(class_names[idx])\n",
        "                    #col_df = pd.DataFrame(col)\n",
        "                    #col_df.to_csv('label.csv', index=False)\n",
        "                    #print('filename = ' + os.path.basename(item), end=' ')\n",
        "                    #print('class = ',x.item())\n",
        "                \n",
        "                \"\"\"\n",
        "                if phase == 'val':\n",
        "                  for item in paths:\n",
        "                    arr = \"\"\n",
        "                    if item != ',':\n",
        "                      arr = arr + item\n",
        "                    arr = os.path.basename(arr)\n",
        "                    print('filename = ' + arr, end='  ')\n",
        "                \"\"\"\n",
        "\n",
        "            if phase == 'train':\n",
        "                # 更新 scheduler\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # 記錄最佳模型\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                best_1 = temp_1\n",
        "                best_2 = temp_2\n",
        "\n",
        "\n",
        "    # 計算耗費時間\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # 輸出最佳準確度\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # 載入最佳模型參數\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    torch.save(model.state_dict(),\"model.pt\")\n",
        "\n",
        "    #output csv\n",
        "    col['filename'] = best_1\n",
        "    col['category'] = best_2\n",
        "    col_df = pd.DataFrame(col)\n",
        "    col_df.to_csv('label.csv', index=False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3vVmgFurTaU"
      },
      "source": [
        "## fine-tuning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpkVFjDErXqo"
      },
      "outputs": [],
      "source": [
        "# 載入 ResNet18 預訓練模型\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "\n",
        "# 取得 ResNet18 最後一層的輸入特徵數量\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "# 將 ResNet18 的最後一層改為只有兩個輸出線性層\n",
        "# 更一般化的寫法為 nn.Linear(num_ftrs, len(class_names))\n",
        "model_ft.fc = nn.Linear(num_ftrs, 219)\n",
        "\n",
        "# 將模型放置於 GPU 或 CPU\n",
        "model_ft = model_ft.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGx4_BDJrqJP"
      },
      "outputs": [],
      "source": [
        "# 使用 cross entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 學習優化器\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# 每 7 個 epochs 將 learning rate 降為原本的 0.1 倍\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46dhIEgfsfLs"
      },
      "source": [
        "## start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ShxeRud3r01f"
      },
      "outputs": [],
      "source": [
        "# 訓練模型\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNjFGxngxyWX"
      },
      "source": [
        "## predict model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYDnCDnTx2H3"
      },
      "outputs": [],
      "source": [
        "# 使用模型進行預測，並顯示結果\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training # 記錄模型之前的模式\n",
        "    model.eval() # 將模型設定為驗證模式\n",
        "\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # 以 DataLoader 載入 batch 資料\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            # 將資料放置於 GPU 或 CPU\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # 使用模型進行預測\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # 顯示預測結果與圖片\n",
        "            for j in range(inputs.size()[0]):      #inputs.size() => torch.Size([4, 3, 224, 224])\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "\n",
        "                # 將 Tensor 轉為原始圖片\n",
        "                img = tensor2img(inputs.cpu().data[j])\n",
        "\n",
        "                ax.imshow(img)\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training) # 恢復模型之前的模式\n",
        "                    return\n",
        "\n",
        "        model.train(mode=was_training) # 恢復模型之前的模式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW8jtGAfyp5b"
      },
      "outputs": [],
      "source": [
        "# 以模型進行預測\n",
        "#visualize_model(model_ft)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0UvmWqwvdLps",
        "UNjFGxngxyWX"
      ],
      "name": "resnet18.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}